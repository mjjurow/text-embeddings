{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babd6391",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a4cdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from openai import OpenAI  # Make sure to replace this with actual API initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7f91d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "# Access the API key from the environment\n",
    "OpenAI.api_key = os.getenv('OPENAI_API_KEY')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203c4998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the directory where articles are saved\n",
    "sample_data_directory = \"wikipedia_articles\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8aca95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process a single file and return its data\n",
    "def process_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "    \n",
    "    # Example: Use the first paragraph as a summary\n",
    "    paragraphs = content.split('\\n\\n')\n",
    "    summary = paragraphs[0].strip() if paragraphs else \"\"\n",
    "    main_text = '\\n\\n'.join(paragraphs[1:]).strip() if len(paragraphs) > 1 else \"\"\n",
    "\n",
    "    # No timestamp available, so we use None or a placeholder\n",
    "    timestamp = None\n",
    "    \n",
    "    return [[summary, main_text, timestamp]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229da0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to store all data\n",
    "all_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ece1cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through all text files in the directory and process them\n",
    "for root, dirs, files in os.walk(sample_data_directory):\n",
    "    for file in files:\n",
    "        if file.endswith(\".txt\"):\n",
    "            file_path = os.path.join(root, file)\n",
    "            file_data = process_file(file_path)\n",
    "            all_data.extend(file_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f62315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with the combined data\n",
    "df = pd.DataFrame(all_data, columns=['Summary', 'Text', 'Timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066a181c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract summaries into a list\n",
    "summaries_list = df['Summary'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3dfab9f",
   "metadata": {},
   "source": [
    "## String search: this code is independent of LLM providers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce7fb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the search function\n",
    "def find_summaries(search_string, summaries):\n",
    "    locations = [index for index, summary in enumerate(summaries) if search_string.lower() in summary.lower()]\n",
    "    return locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b6ead9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "search_string = \"some search string\"\n",
    "locations = find_summaries(search_string, summaries_list)\n",
    "print(f\"Summaries containing '{search_string}' are found at indices: {locations}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3da219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the actual summaries found for verification\n",
    "for loc in locations:\n",
    "    print(f\"\\nSummary at index {loc}:\\n{summaries_list[loc]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198f687a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Embedding code for OpenAI:\n",
    "openai_model_name = 'text-search-ada-query-001'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc709b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get embeddings for a list of texts in batches\n",
    "def get_embeddings(texts, client, model=openai_model_name, batch_size=20):\n",
    "    embeddings = []\n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i:i + batch_size]\n",
    "        try:\n",
    "            response = client.embeddings.create(input=batch, model=model)\n",
    "            # Adding detailed debug information\n",
    "            #print(f\"Response: {response}\")\n",
    "            for res in response.data:\n",
    "                #print(f\"Embedding: {res.embedding}\")\n",
    "                embeddings.append(res.embedding)\n",
    "        except Exception as e:\n",
    "            print(f\"Error getting embeddings: {e}\")\n",
    "    embeddings = np.array(embeddings)\n",
    "    #print(f\"Embeddings shape: {embeddings.shape}\")  # Check the shape of embeddings\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ae99fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to prepare and index embeddings for summaries\n",
    "def prepare_index(summaries, client, model=openai_model_name, batch_size=20):\n",
    "    embeddings = get_embeddings(summaries, client, model, batch_size)\n",
    "    if len(embeddings) == 0:\n",
    "        raise ValueError(\"No embeddings were generated.\")\n",
    "    dimension = embeddings.shape[1]\n",
    "    index = faiss.IndexFlatL2(dimension)\n",
    "    index.add(embeddings.astype('float32'))\n",
    "    return index, embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f4ae2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to retrieve relevant summaries based on a query\n",
    "def retrieve_summaries(query, summaries, client, model=openai_model_name, threshold=0.75, batch_size=20):\n",
    "    index, embeddings = prepare_index(summaries, client, model, batch_size)\n",
    "    query_embedding = get_embeddings([query], client, model, batch_size=batch_size).astype('float32').reshape(1, -1)\n",
    "    D, I = index.search(query_embedding, len(summaries))\n",
    "    similarities = 1 - (D / np.max(D))\n",
    "    relevant_summaries = [summaries[i] for i, similarity in zip(I[0], similarities[0]) if similarity > threshold]\n",
    "    relevant_similarities = [similarity for similarity in similarities[0] if similarity > threshold]\n",
    "    return relevant_summaries, relevant_similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cbc5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing with a single summary\n",
    "single_summary_list = summaries_list[:1]\n",
    "query = \"enter some search query here\"\n",
    "threshold = 0.3  # THIS IS A CRITICAL VARIABLE\n",
    "results = retrieve_summaries(query, single_summary_list, client, model=\"text-embedding-3-small\", threshold=threshold)\n",
    "relevant_summaries, relevant_similarities = results\n",
    "#print(\"Relevant summaries:\", relevant_summaries)\n",
    "#print(\"Relevant similarities:\", relevant_similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65310d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the results\n",
    "for idx, (summary, similarity) in enumerate(zip(relevant_summaries, relevant_similarities)):\n",
    "    print(f\"Summary {idx+1} (Similarity: {similarity:.2f}):\\n{summary}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
